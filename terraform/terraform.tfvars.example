# DigitalOcean API Token
digitalocean_token = "dop_v1_your_personal_access_token_here"

# DigitalOcean Spaces Credentials (required for object storage / searchable snapshots)
# Generate these at: https://cloud.digitalocean.com/account/api/spaces
spaces_access_id  = "your_spaces_access_key_id_here"
spaces_secret_key = "your_spaces_secret_key_here"

# DigitalOcean Configuration
region = "nyc3"

# Cluster Configuration
cluster_name = "elasticsearch"
environment  = "poc"

# SSH Configuration - REQUIRED
# Provide your SSH public key content. Terraform will create the SSH key in DigitalOcean.
# Get your public key with: cat ~/.ssh/id_ed25519.pub (or id_rsa.pub)
ssh_public_key = "ssh-ed25519 AAAAC3... your-email@example.com"

# Optional: Custom name for the SSH key in DigitalOcean (defaults to "elasticsearch-cluster-key")
# ssh_key_name = "my-custom-key-name"

# Elasticsearch Node Configuration
# Define any number of node types with different roles and configurations

# SINGLE NODE (Minimal demo - ~$18/month):
elasticsearch_nodes = {
  hot = {
    count = 1
    size  = "s-2vcpu-2gb"
    roles = ["master", "data_hot", "ingest", "remote_cluster_client"]
  }
}

# 3-NODE CLUSTER (Demo/POC - ~$54/month):
# elasticsearch_nodes = {
#   hot = {
#     count = 3
#     size  = "s-2vcpu-2gb"
#     roles = ["master", "data_hot", "ingest", "remote_cluster_client"]
#   }
# }

# MULTI-TIER CLUSTER (Production - ~$168/month):
# elasticsearch_nodes = {
#   hot = {
#     count = 3
#     size  = "s-4vcpu-8gb"
#     roles = ["master", "data_hot", "ingest", "remote_cluster_client"]
#   }
#   cold = {
#     count = 1
#     size  = "s-1vcpu-2gb"
#     roles = ["data_cold", "remote_cluster_client"]
#   }
#   frozen = {
#     count = 1
#     size  = "s-1vcpu-2gb"
#     roles = ["data_frozen", "remote_cluster_client"]
#   }
# }

# Elasticsearch Version
# Using 9.1.5 - latest stable version as of October 2025
elasticsearch_version = "9.1.5"

# Deployment Mode
# "airgapped"        - Self-managed: Pre-download packages and upload via Terraform (no internet required on droplets)
# "networked"        - Self-managed: Install packages directly from internet repositories (droplets need internet access)
# "cloud_hosted"     - Elastic Cloud hosted deployment
# "cloud_serverless" - Elastic Cloud serverless deployment
deployment_mode = "airgapped"

# Security Configuration
# WARNING: Default opens access to the entire internet.
# IMPORTANT: Restrict to specific IP addresses or CIDR blocks in production

# API Access - who can access Elasticsearch through the load balancer
allowed_ips = ["0.0.0.0/0"]  # CHANGE THIS IN PRODUCTION

# SSH Access - more restrictive, only for administrators
# Leave empty to use same as allowed_ips, or specify separate IPs
allowed_ssh_ips = []

# Example for restricted access:
# allowed_ips = [
#   "203.0.113.0/24",    # Office network for API access
#   "198.51.100.15/32"   # Specific monitoring server
# ]
# allowed_ssh_ips = [
#   "198.51.100.15/32",  # Admin workstation only
#   "203.0.113.10/32"    # Jump server
# ]

# Spaces Configuration
# Leave empty to auto-generate name, or specify your own
spaces_bucket_name = ""

# Monitoring
enable_monitoring = true

# Node Sizes for Kibana, EPR, and Artifact Registry
# The full Elastic stack includes these services by default
# DEMO cost (with defaults below): ~$1.20/day
# PRODUCTION cost (larger sizes): ~$1.60/day
# kibana_node_size            = "s-1vcpu-2gb"  # Uncomment to override default
# epr_node_size               = "s-1vcpu-2gb"  # Uncomment to override default
# artifact_registry_node_size = "s-1vcpu-2gb"  # Uncomment to override default

# Data Source Configuration - Cribl Stream
# Optional VMs for sending data to Elasticsearch via Cribl Stream
# Set cribl_stream_count > 0 to enable (0 = disabled)

cribl_stream_count = 0  # Number of Cribl Stream VMs (0 to disable, 1-10 to enable)

# Uncomment to enable Cribl Stream:
# cribl_stream_count     = 1              # Create 1 Cribl Stream instance
# cribl_stream_node_size = "s-2vcpu-4gb"  # Recommended: s-2vcpu-4gb (~$24/month)
# cribl_stream_version   = "4.8.2"        # Cribl Stream version
# cribl_leader_mode      = "standalone"   # "standalone" or "worker"

# Worker mode configuration (only if cribl_leader_mode = "worker"):
# cribl_leader_url   = "https://your-leader-url:4200"
# cribl_auth_token   = "your-worker-auth-token"